{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403c6160-0270-487d-8ea3-80426757b606",
   "metadata": {},
   "source": [
    "## Installers here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc1ed7c2-1648-4dd9-9e57-b73cc7285823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install transformers\n",
    "#! pip install langchain-chroma\n",
    " #! pip install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6511f7f6-ece6-4303-9d77-c8f80e277a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -U langchain-huggingface sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df09cdd-12a2-4954-9749-c06fcd73d666",
   "metadata": {},
   "source": [
    "## Loading the documents into the RAG ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af7d50c-1324-4063-9926-9d371d6db4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 378.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the documents\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = DirectoryLoader('data/alzheimers', glob=\"*.txt\", show_progress=True, loader_cls=TextLoader)\n",
    "\n",
    "kb_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a775d67-327e-4124-8483-b850314dddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk the loaded documents\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=50)\n",
    "\n",
    "chunks = text_splitter.split_documents(kb_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a5e2abd-d2e0-4529-a490-a42909124e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hugging face embedding model is used as I am not having openAI key access and usage restrictions.\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",  # Free, local\n",
    "    # model_kwargs={\"device\": \"cuda\"}  # GPU acceleration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdb8b2b1-3d27-44ee-9d3e-27783f0b8def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialize the Chroma DB Connection\n",
    "# Initialize a ChromaDB Connection\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Initialize the database connection\n",
    "# If database exist, it will connect with the collection_name and persist_directory\n",
    "# Otherwise a new collection will be created\n",
    "db = Chroma(collection_name=\"vector_database\", \n",
    "            embedding_function=embedding_model, \n",
    "            persist_directory=\"./chroma_db_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c84606e0-dd76-4709-bbdb-b97fbb3a6bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9b0e8009-9908-4e53-bb7c-aa7801d44fc7',\n",
       " 'b0567ecd-3f01-4caa-95a3-3786660a7109',\n",
       " '3c3ecd06-5217-4e99-b7df-129796c4aae7',\n",
       " 'd178f307-9836-4958-a5b7-7abd5f619d7b',\n",
       " '96ff63b9-6d54-43c4-aad1-069b1af00d3f',\n",
       " 'a1dd825d-0b79-4669-8252-fbef7886bfca',\n",
       " '99e970e8-f0f6-4070-b81d-5554bfeb082e',\n",
       " '2f293577-e84f-4e32-9d07-da8056345846',\n",
       " 'a9f9b67e-9601-44ba-abe8-887f96ded24e',\n",
       " '075430ca-9745-4c80-9ab7-34816b99c5f4',\n",
       " '617506a2-5239-45a8-8367-0422910494d1',\n",
       " 'b5bc71dd-ce03-4f3a-a835-18c2c0ccdef0',\n",
       " '2784510c-3a85-41c8-8bd4-2c18dccb0e4f',\n",
       " '0423b71d-6a3e-4e9f-97c4-aa6b47458379',\n",
       " '064beaf9-b618-48a2-8f0c-9aa29fe3b25b',\n",
       " 'f4c106fd-ffa5-4563-9a73-964b56e0a61b',\n",
       " 'df6c6fd0-e204-49e0-bf14-61a152c8628a',\n",
       " 'b38eb7eb-9103-40e1-97d4-a550c86775da',\n",
       " '4e88ff08-5eb5-4b06-a05e-f747e92b11cf',\n",
       " '9987eef4-d6ca-48fc-a4e6-39f0752938d6',\n",
       " '7067cb12-5feb-473d-b747-ac24bba57579',\n",
       " '448fe996-b407-4c8a-9ff4-da0896bfd885',\n",
       " '6e027a3c-5df6-450f-b29e-e381c8ab81bd',\n",
       " '24ea610b-591d-4b5f-834b-27b7577b9c23',\n",
       " 'a5c3fa35-40b2-45b6-abc3-614152b14e07',\n",
       " '6b777fba-49e8-441b-b9cd-4dfb8d5b14ab',\n",
       " '9347b5c7-a614-4271-9b39-c9afca88df23',\n",
       " '1d5d2875-c9f8-4382-8354-15ddf99e7804',\n",
       " 'ff00a586-f6ec-43b4-adef-c9e16f4e2b98',\n",
       " '10f8fb7a-b5fe-476a-bc17-60a11d963ca1',\n",
       " 'c7ca6982-31ba-4df3-80c3-4474363b54f0',\n",
       " '9d35bed3-4d8b-45d7-ac97-ff599eaec724',\n",
       " '33b644d9-60a7-4af7-a82b-c3e4fa39e8a4',\n",
       " 'b9149caf-1c71-45c4-8ad2-fee5f4f7696b',\n",
       " 'b9dc125c-b4d0-4bbe-b6c0-06c334b3130b',\n",
       " 'c333eec7-4738-4ded-a8e0-beca19a9a9b1',\n",
       " 'c3840fb0-b8f2-45f6-bbcf-06b3c8ecbc9c',\n",
       " '7a4762f8-6744-48aa-a942-161838355f90',\n",
       " 'c698daa2-5b54-457b-b588-2ddef6d31364',\n",
       " 'ddfb34cf-8aac-4789-aa88-d68c5a3e1ce4',\n",
       " '28ae3f09-dd88-4215-b689-da47d9a69ba6',\n",
       " 'b432359b-34d6-4921-8160-d1e5726a8157',\n",
       " '743367ac-8ee5-4e74-b56c-552eaa5d72d0',\n",
       " 'c9783b05-7fad-4bdd-bf65-cfb8dc421d01',\n",
       " '11c606a8-dfe5-4d35-87fc-dda37f3fbe7f',\n",
       " '6f67687c-d2a6-4c8a-b00e-ce2e5654b5c8',\n",
       " '37d906eb-6dc9-43ce-85c7-ded018151cac',\n",
       " '1bb9736e-ba74-4f9b-b26f-0d7d68566907',\n",
       " '0e7db479-6373-4c68-b096-a51b7cbfa648',\n",
       " 'b9798897-7be7-4ba6-a5e8-8cd406196595',\n",
       " '34212474-e3e1-446f-ba80-ad48770acefa',\n",
       " '5def8b2a-451e-45c8-a056-3b49d8fc9822',\n",
       " '688f763b-e250-4a9e-8cd0-8dd7fdfd4bdf',\n",
       " 'a3712c69-4cad-46fe-b2af-e560e65078de',\n",
       " '60c0fad6-9149-423c-a169-3cf5985d3e08',\n",
       " '7c20b628-b345-4291-9ce4-105acd4a5ef2',\n",
       " 'f360bcd3-319a-48a8-9401-5d65459e2c34',\n",
       " '229a541d-6ab0-4eab-9430-2a41b4c1b6ac',\n",
       " 'b78f6e76-c138-4dc6-993e-e662670d52fb',\n",
       " '169de9a6-9b82-4261-a388-f63a57005cb4',\n",
       " '4cdabdf1-b020-4fba-b3d1-c2fb41ced91f',\n",
       " '18f5cda5-bdcf-488a-832b-c13654dda5f6',\n",
       " '036dcea6-eb1a-477c-8cee-1524fb24bdea',\n",
       " 'ecad42bf-f953-4826-b9f5-b3273fbabc46',\n",
       " '1193e814-f3f0-43ef-a4f0-17aa9ca78968',\n",
       " 'ecdf3ec7-1f42-4d88-baef-15ed29194ef8',\n",
       " '445f06d3-462e-4d7b-ba1f-ba5399b6ca81',\n",
       " '5619172b-1b0d-4c05-b8d1-41f4e86c4bd7',\n",
       " '849fe76a-ef8f-4de1-839f-de40113417a1',\n",
       " 'd7d3f479-3f7a-44ae-8094-d0b89e9dd270',\n",
       " 'fa9cf6d8-7e3d-4e6b-aaf5-1c9ad3fccb70',\n",
       " 'd43dbba9-56a9-492f-b42b-a4d7ccc2ff05',\n",
       " '8b1a5530-5687-4c18-adae-3d019d40fe66',\n",
       " 'e21e6946-26c5-45f9-acd2-4fa9eb0f5385',\n",
       " '62208ecc-fd1e-45bf-b3e2-dbc781e6d8b9',\n",
       " '9a716a06-749c-4afd-a3c6-48134b3b429e',\n",
       " '3327a0f8-60a3-4485-9a3e-4bc98b0eda0f',\n",
       " '2999d362-ef85-44e2-b3ef-b8bd82d8d7f8',\n",
       " '9e9ee82b-5a0a-43b1-8555-247ee596e71b',\n",
       " 'b5451db2-47cc-49df-a3f3-401e6bddc637',\n",
       " 'ce62ba6f-7afe-4660-a784-93f6f9a852c8',\n",
       " 'b0a00289-10f8-4194-b22e-f5e76d3ad1a8',\n",
       " '3dbc0cab-472d-460c-91ed-c66802e66279',\n",
       " '08c48e0e-263d-4c55-8206-aff68f67c0b6',\n",
       " '507e05a4-57c6-41c5-9290-d2f41537967e',\n",
       " 'd95b7d57-57b5-496a-a93f-6e513706b998',\n",
       " 'd9f0d043-08d7-4a37-a3bb-284f8b643219',\n",
       " 'fcbd6ce8-2719-4f31-83b5-ef8325466a08',\n",
       " '41e2060c-6ba8-4439-bd12-a18ce1ee4f81',\n",
       " 'cae1cf78-de84-4c2c-bc2e-d70721c68099',\n",
       " 'c9113dc5-86a2-4451-ab41-88be40ce23f5',\n",
       " 'add64622-bd3b-4b10-9dac-589f0ced3bb5',\n",
       " 'd04d7954-ee8d-4a11-8d1c-26b65283fa91',\n",
       " 'e1a78a2f-fe68-4536-930e-2ae4f5315050',\n",
       " 'fae9075a-9561-4c92-91c1-a4935d57d7bd',\n",
       " '708d6402-e61b-4395-b91a-1b52902204b9',\n",
       " '2369dcad-1b06-4105-aecc-441e0e7ccb40',\n",
       " '77b76306-05ab-45c5-b985-a081e0cb6ada',\n",
       " '18245f5b-2bd0-42df-b1a6-4316d0ab9ed4',\n",
       " '51dd7138-ca33-46d2-a2f9-2005a9485556',\n",
       " 'd93b4038-eb36-4d1c-b441-63aed18a2fb9',\n",
       " '702c5ea0-c63e-472d-a970-634d3365ea35',\n",
       " '27de76e1-2dee-4a6e-b0f5-c87d56453113',\n",
       " '869db0af-467c-4638-a978-b91701309b90',\n",
       " 'f8682fc0-f1b6-4f0e-92c8-c86cc119912b',\n",
       " 'e1e26caa-bae4-4e2f-8f10-01a62b1fd0b3',\n",
       " 'cc1010a2-a402-4ae3-8a87-2b1cd173dd36',\n",
       " 'e8743b5b-b586-4669-ace7-fdcccce21ef2',\n",
       " 'ba32919b-9fc8-4fb0-b1d9-6153b5f02bb3',\n",
       " 'b4d0df40-4799-4da2-a7db-4d8dd274366e',\n",
       " 'bc0d85f8-a68e-47fa-b7e5-0d638777eeab',\n",
       " '7f0d5452-a323-404f-825a-088dc4495bd5',\n",
       " '0863cee4-568f-4065-91b8-bcad642c825e',\n",
       " '7d29835b-c438-47c9-9431-51875e844f19',\n",
       " '7f221115-fae7-49b7-820c-c7de6d5829e2',\n",
       " '8abbf574-8738-4c82-b27b-ace8465a5f63',\n",
       " '4225c6d7-f1b8-4e90-b02c-b57ae6f14cc3',\n",
       " 'ab3ecac3-0c83-49ea-98bf-2501d1a734ad',\n",
       " '4bc04503-e7d7-45ac-bca3-8d2618225a6a',\n",
       " '91c4bf30-337f-43e8-8b7c-2341c6731372',\n",
       " 'c80e0acb-0a64-42ca-9a54-18caf82a32c8',\n",
       " 'ebbce782-70a6-4c86-8391-82d617ae6135',\n",
       " 'a429e8d6-c503-4ba3-86f6-da5f73637d87']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert chunks in the vector database\n",
    "\n",
    "db.add_documents(documents=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a5fc4a5-da66-4d29-a4ad-08c90e97e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create a Retriever Object \n",
    "\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05b45735-6688-4265-878d-50deb502e31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='84d66514-34e6-4dba-9569-c5510aa91d66', metadata={'source': 'data\\\\alzheimers\\\\alzheimers_3.txt'}, page_content='Techniques'),\n",
       " Document(id='ce62ba6f-7afe-4660-a784-93f6f9a852c8', metadata={'source': 'data\\\\alzheimers\\\\alzheimers_3.txt'}, page_content='Techniques'),\n",
       " Document(id='efb42a31-115e-466a-b67e-d07af6d6a1b0', metadata={'source': 'data\\\\alzheimers\\\\alzheimers_2.txt'}, page_content='Disease mechanism'),\n",
       " Document(id='169de9a6-9b82-4261-a388-f63a57005cb4', metadata={'source': 'data\\\\alzheimers\\\\alzheimers_2.txt'}, page_content='Disease mechanism')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"explain design patterns \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31f5362e-6cb8-400e-9ab5-815b78ba9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Initialize a Chat Prompt Template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "Answer the question based on the above context: {question}.\n",
    "\n",
    "show the context that was passed.\n",
    "Provide a detailed answer.\n",
    "Don’t justify your answers.\n",
    "Don’t give information not mentioned in the CONTEXT INFORMATION.\n",
    "Do not say \"according to the context\" or \"mentioned in the context\" or similar.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        PROMPT_TEMPLATE\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ccbc520-a49b-408c-af2b-028a4351d08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-huggingface in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: huggingface_hub in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (0.36.2)\n",
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-1.4.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from langchain-huggingface) (1.2.13)\n",
      "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from langchain-huggingface) (0.22.2)\n",
      "Requirement already satisfied: filelock in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from huggingface_hub) (3.24.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from huggingface_hub) (2026.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from huggingface_hub) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from huggingface_hub) (6.0.3)\n",
      "Requirement already satisfied: requests in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from huggingface_hub) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from huggingface_hub) (4.67.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.7.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.12.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (9.1.4)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.14.0)\n",
      "Requirement already satisfied: colorama in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from requests->huggingface_hub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from requests->huggingface_hub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from requests->huggingface_hub) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from requests->huggingface_hub) (2026.1.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.6.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.4.2)\n",
      "Requirement already satisfied: anyio in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\training\\ai\\handsonlabs\\langchain_experiments\\.venv_langchain\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install -U langchain-huggingface huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f65c2f93-02b1-498c-a782-f6bba4993f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Initialize a Generator (i.e. Chat Model)\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain_huggingface import ChatHuggingFace  # Optional chat wrapper\n",
    "\n",
    "f = open(\"keys/.huggingface_token.txt\")\n",
    "HUGGINGFACE_TOKEN = f.read()\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    temperature=0.7,\n",
    "    model=\"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=HUGGINGFACE_TOKEN  # Free token from huggingface.co\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)  # Chat interface like ChatOpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "080482d6-7e94-4a78-bff8-9d9fa8bf4921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 30, 'total_tokens': 40}, 'model_name': 'Qwen/Qwen2.5-7B-Instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c8548-49b6-7333-be12-81b3fa0b632e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 30, 'output_tokens': 10, 'total_tokens': 40})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "947193e5-cf66-4eee-bff0-8b2c44df6fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c3091d6-e1c9-450d-9090-7b79e614b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_chain = prompt_template | chat_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48411d22-dad2-46a8-a723-e397c5154aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to join the retrieved chunks\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f44929ec-61a9-4e83-a838-6d36a1ecee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define a RAG Chain\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = {\n",
    "    \"context\": retriever | format_docs, \n",
    "    \"question\": RunnablePassthrough()\n",
    "} | generator_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af07c5d5-4307-422c-ab4d-8838a043957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['answer', 'context', 'question'])\n",
      "Context sent to the LLM:\n",
      " Techniques\n",
      "\n",
      "Techniques\n",
      "\n",
      "Disease mechanism\n",
      "\n",
      "Disease mechanism\n",
      "\n",
      "Answer:\n",
      " content='The context provided does not contain any information about the 1983 cricket worldcup.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 122, 'total_tokens': 142}, 'model_name': 'Qwen/Qwen2.5-7B-Instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c8548-565d-7b91-9bee-ce44955a1632-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 122, 'output_tokens': 20, 'total_tokens': 142}\n",
      "\n",
      "Question:\n",
      " What won 1983 cricket worldcup?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "# Your original inputs\n",
    "inputs = {\n",
    "    \"context\": retriever | format_docs,\n",
    "    \"question\": RunnablePassthrough()\n",
    "}\n",
    "\n",
    "# The original chain to generate the answer from the inputs\n",
    "rag_chain = inputs | generator_chain\n",
    "\n",
    "# New chain that returns both the context and the final answer\n",
    "rag_chain_with_context = RunnableParallel(\n",
    "    answer=rag_chain,                # final output\n",
    "    context=inputs[\"context\"],       # resolved context\n",
    "    question=inputs[\"question\"],     # optional, keep if you want to see it too\n",
    ")\n",
    "\n",
    "result = rag_chain_with_context.invoke(\"What won 1983 cricket worldcup?\")\n",
    "print(result.keys())\n",
    "print(\"Context sent to the LLM:\\n\", result[\"context\"])\n",
    "print(\"\\nAnswer:\\n\", result[\"answer\"])\n",
    "print(\"\\nQuestion:\\n\",result[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed115f88-775e-4936-9e84-1bb2aec7d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the Chain\n",
    "\n",
    "query = 'explain about Fifa WorldCup?'\n",
    "\n",
    "result = rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b07ae00a-c7a5-4336-bb85-443c1a5655ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The context provided does not contain any information about the FIFA World Cup. The context is about disease mechanisms and techniques related to them.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 119, 'total_tokens': 146}, 'model_name': 'Qwen/Qwen2.5-7B-Instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c8548-6054-7c51-abaa-5987ef9a37a6-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 119, 'output_tokens': 27, 'total_tokens': 146}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b01e29b-0d30-470c-a178-1f6e899691aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The context provided does not contain any information about how to play football. The given text discusses intellectual activities and social interactions in relation to Alzheimer's disease risk but does not mention football or provide instructions on how to play it.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 177, 'total_tokens': 222}, 'model_name': 'Qwen/Qwen2.5-7B-Instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c8548-643f-7542-ae38-b0ee9d21533b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 177, 'output_tokens': 45, 'total_tokens': 222})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"how to play football\"\n",
    "rag_chain.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
